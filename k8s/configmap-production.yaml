# Kubernetes ConfigMaps for AI Conversation System

apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-conversation-config
  namespace: ai-conversation
  labels:
    app: ai-conversation-system
    component: config
data:
  # Application Settings
  ENVIRONMENT: "production"
  DEBUG: "false"
  LOG_LEVEL: "WARNING"
  APP_NAME: "AI Conversation System"
  APP_VERSION: "1.0.0"
  API_PREFIX: "/api/v1"
  
  # Server Settings
  HOST: "0.0.0.0"
  PORT: "8000"
  WORKERS: "1"
  
  # Database Settings
  DB_HOST: "postgres-master-service"
  DB_PORT: "5432"
  DB_NAME: "ai_conversation"
  DB_POOL_SIZE: "30"
  DB_MAX_OVERFLOW: "50"
  DB_POOL_TIMEOUT: "30"
  DB_POOL_RECYCLE: "3600"
  
  # Redis Cluster Settings
  REDIS_CLUSTER_ENABLED: "true"
  REDIS_CLUSTER_NODES: "redis-0.redis-headless:6379,redis-1.redis-headless:6379,redis-2.redis-headless:6379"
  REDIS_MAX_CONNECTIONS: "100"
  REDIS_MIN_CONNECTIONS: "10"
  REDIS_CACHE_TTL: "3600"
  REDIS_SESSION_TTL: "86400"
  REDIS_RATE_LIMIT_TTL: "3600"
  REDIS_MAX_MEMORY_POLICY: "allkeys-lru"
  REDIS_COMPRESSION_ENABLED: "true"
  
  # ML Settings
  ML_DEVICE: "cpu"
  ML_MODEL_PATH: "/app/models"
  ML_BATCH_SIZE: "32"
  ML_MAX_SEQUENCE_LENGTH: "512"
  ML_ENABLE_GPU: "false"
  ML_MODEL_CACHE_SIZE: "5"
  ML_SENTIMENT_MODEL: "cardiffnlp/twitter-roberta-base-sentiment-latest"
  ML_EMBEDDING_MODEL: "sentence-transformers/all-MiniLM-L6-v2"
  
  # Celery Settings
  CELERY_BROKER_URL: "redis-cluster://redis-0.redis-headless:6379,redis-1.redis-headless:6379,redis-2.redis-headless:6379/1"
  CELERY_RESULT_BACKEND: "redis-cluster://redis-0.redis-headless:6379,redis-1.redis-headless:6379,redis-2.redis-headless:6379/2"
  CELERY_WORKER_CONCURRENCY: "4"
  CELERY_TASK_TIME_LIMIT: "300"
  CELERY_TASK_SOFT_TIME_LIMIT: "240"
  CELERY_DEFAULT_QUEUE: "default"
  CELERY_ML_QUEUE: "ml_tasks"
  CELERY_TASK_MAX_RETRIES: "3"
  CELERY_TASK_RETRY_DELAY: "60"
  
  # Telegram Settings
  TELEGRAM_WEBHOOK_URL: "https://your-domain.com/webhook"
  TELEGRAM_RATE_LIMIT_CALLS: "20"
  TELEGRAM_RATE_LIMIT_PERIOD: "60"
  TELEGRAM_PARSE_MODE: "HTML"
  
  # Security Settings
  JWT_ALGORITHM: "HS256"
  JWT_EXPIRATION_SECONDS: "3600"
  RATE_LIMIT_ENABLED: "true"
  RATE_LIMIT_PER_MINUTE: "120"
  RATE_LIMIT_PER_HOUR: "5000"
  RATE_LIMIT_PER_IP_PER_MINUTE: "10"
  ENABLE_SECURITY_HEADERS: "true"
  HSTS_MAX_AGE: "31536000"
  MAX_REQUEST_SIZE: "10485760"
  MAX_JSON_SIZE: "1048576"
  ENABLE_INPUT_SANITIZATION: "true"
  CORS_ORIGINS: "https://your-domain.com"
  
  # Advanced Typing Settings
  ENABLE_ADVANCED_TYPING: "true"
  ENABLE_TYPING_CACHING: "true"
  MAX_TYPING_SESSIONS: "1000"
  TYPING_CACHE_TTL: "300"
  TYPING_SESSION_TIMEOUT: "60"
  MAX_SIMULATION_TIME: "30.0"
  MIN_SIMULATION_TIME: "0.3"
  ENABLE_ERROR_SIMULATION: "true"
  ENABLE_PAUSE_SIMULATION: "true"
  ENABLE_ANTI_DETECTION: "true"
  PATTERN_RANDOMIZATION_LEVEL: "0.3"
  ENABLE_PERSONALITY_TYPING: "true"
  PERSONALITY_ADAPTATION_STRENGTH: "0.7"
  
  # Monitoring Settings
  METRICS_ENABLED: "true"
  METRICS_PORT: "8001"
  HEALTH_CHECK_INTERVAL: "30"
  SENTRY_ENVIRONMENT: "production"
  LOG_FORMAT: "json"
  
  # Feature Flags
  ENABLE_CONTENT_FILTERING: "true"
  ENABLE_URL_VALIDATION: "true"
  ENABLE_DATA_ENCRYPTION: "true"
  ENABLE_SECURITY_MONITORING: "true"
  SECURITY_ALERT_THRESHOLD: "5"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-conversation-gpu-config
  namespace: ai-conversation
  labels:
    app: ai-conversation-system
    component: gpu-config
data:
  # GPU-specific ML Settings
  ML_DEVICE: "cuda"
  ML_ENABLE_GPU: "true"
  ML_BATCH_SIZE: "64"
  CUDA_VISIBLE_DEVICES: "all"
  NVIDIA_VISIBLE_DEVICES: "all"
  TORCH_CUDA_ARCH_LIST: "6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0"
  OMP_NUM_THREADS: "1"
  OPENBLAS_NUM_THREADS: "1"
  MKL_NUM_THREADS: "1"
  
  # GPU Worker Settings
  CELERY_WORKER_CONCURRENCY: "2"  # Lower concurrency for GPU memory
  
  # GPU Monitoring
  ENABLE_GPU_MONITORING: "true"
  GPU_MEMORY_LIMIT: "80"  # Percentage
  GPU_UTILIZATION_THRESHOLD: "90"  # Percentage

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: ai-conversation
  labels:
    app: ai-conversation-system
    component: nginx
data:
  nginx.conf: |
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log warn;
    pid /var/run/nginx.pid;
    
    events {
        worker_connections 1024;
        use epoll;
        multi_accept on;
    }
    
    http {
        include /etc/nginx/mime.types;
        default_type application/octet-stream;
        
        # Logging
        log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for" '
                        'rt=$request_time uct="$upstream_connect_time" '
                        'uht="$upstream_header_time" urt="$upstream_response_time"';
        
        access_log /var/log/nginx/access.log main;
        
        # Performance
        sendfile on;
        tcp_nopush on;
        tcp_nodelay on;
        keepalive_timeout 65;
        types_hash_max_size 2048;
        client_max_body_size 10M;
        
        # Gzip compression
        gzip on;
        gzip_vary on;
        gzip_min_length 10240;
        gzip_proxied expired no-cache no-store private must-revalidate;
        gzip_types
            text/plain
            text/css
            text/xml
            text/javascript
            application/x-javascript
            application/xml+rss
            application/javascript
            application/json;
        
        # Rate limiting
        limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
        limit_req_zone $binary_remote_addr zone=webhook:10m rate=100r/s;
        
        # Upstream servers
        upstream app_backend {
            least_conn;
            server ai-conversation-app-0.ai-conversation-app:8000 max_fails=3 fail_timeout=30s;
            server ai-conversation-app-1.ai-conversation-app:8000 max_fails=3 fail_timeout=30s;
            server ai-conversation-app-2.ai-conversation-app:8000 max_fails=3 fail_timeout=30s;
        }
        
        # Main server block
        server {
            listen 80;
            listen 443 ssl http2;
            server_name your-domain.com;
            
            # SSL configuration
            ssl_certificate /etc/nginx/ssl/tls.crt;
            ssl_certificate_key /etc/nginx/ssl/tls.key;
            ssl_protocols TLSv1.2 TLSv1.3;
            ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
            ssl_prefer_server_ciphers off;
            
            # Security headers
            add_header X-Frame-Options DENY;
            add_header X-Content-Type-Options nosniff;
            add_header X-XSS-Protection "1; mode=block";
            add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
            
            # Health check endpoint
            location /health {
                access_log off;
                return 200 "healthy\n";
                add_header Content-Type text/plain;
            }
            
            # Webhook endpoint with higher rate limit
            location /webhook {
                limit_req zone=webhook burst=20 nodelay;
                proxy_pass http://app_backend;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_connect_timeout 30s;
                proxy_send_timeout 30s;
                proxy_read_timeout 30s;
            }
            
            # API endpoints
            location /api/ {
                limit_req zone=api burst=20 nodelay;
                proxy_pass http://app_backend;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_connect_timeout 30s;
                proxy_send_timeout 30s;
                proxy_read_timeout 30s;
            }
            
            # Metrics endpoint (internal only)
            location /metrics {
                allow 10.0.0.0/8;
                allow 172.16.0.0/12;
                allow 192.168.0.0/16;
                deny all;
                proxy_pass http://app_backend:8001;
            }
            
            # Default location
            location / {
                return 404;
            }
        }
    }
  
  default.conf: |
    # Additional server configurations can be added here

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: ai-conversation
  labels:
    app: ai-conversation-system
    component: postgres
data:
  postgresql.conf: |
    # PostgreSQL Configuration for Production
    
    # Connection settings
    listen_addresses = '*'
    port = 5432
    max_connections = 200
    
    # Memory settings
    shared_buffers = 256MB
    effective_cache_size = 1GB
    maintenance_work_mem = 64MB
    checkpoint_completion_target = 0.9
    wal_buffers = 16MB
    default_statistics_target = 100
    random_page_cost = 1.1
    effective_io_concurrency = 200
    
    # Write-ahead logging
    wal_level = replica
    max_wal_senders = 3
    max_replication_slots = 3
    
    # Checkpoints
    checkpoint_timeout = 10min
    max_wal_size = 2GB
    min_wal_size = 1GB
    
    # Archiving
    archive_mode = on
    archive_command = '/bin/true'  # Replace with actual archive command
    
    # Logging
    logging_collector = on
    log_directory = 'pg_log'
    log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
    log_truncate_on_rotation = on
    log_rotation_age = 1d
    log_rotation_size = 100MB
    log_min_duration_statement = 1000
    log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
    log_checkpoints = on
    log_connections = on
    log_disconnections = on
    log_lock_waits = on
    
    # Performance monitoring
    track_activities = on
    track_counts = on
    track_io_timing = on
    track_functions = pl
    
  pg_hba.conf: |
    # PostgreSQL Client Authentication Configuration
    
    # TYPE  DATABASE        USER            ADDRESS                 METHOD
    
    # Local connections
    local   all             all                                     trust
    
    # Host connections
    host    all             all             127.0.0.1/32            md5
    host    all             all             ::1/128                 md5
    
    # Kubernetes cluster connections
    host    all             all             10.0.0.0/8              md5
    host    all             all             172.16.0.0/12           md5
    host    all             all             192.168.0.0/16          md5
    
    # Replication connections
    host    replication     replicator      10.0.0.0/8              md5
    host    replication     replicator      172.16.0.0/12           md5
    host    replication     replicator      192.168.0.0/16          md5

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: ai-conversation
  labels:
    app: ai-conversation-system
    component: redis
data:
  redis.conf: |
    # Redis Configuration for Production Cluster
    
    # Network settings
    bind 0.0.0.0
    protected-mode no
    port 6379
    tcp-backlog 511
    timeout 0
    tcp-keepalive 300
    
    # General settings
    daemonize no
    supervised no
    pidfile /var/run/redis_6379.pid
    loglevel notice
    logfile ""
    databases 16
    
    # Cluster settings
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 15000
    cluster-announce-ip ${POD_IP}
    cluster-announce-port 6379
    cluster-announce-bus-port 16379
    
    # Persistence settings
    save 900 1
    save 300 10
    save 60 10000
    stop-writes-on-bgsave-error yes
    rdbcompression yes
    rdbchecksum yes
    dbfilename dump.rdb
    dir ./
    
    # AOF settings
    appendonly yes
    appendfilename "appendonly.aof"
    appendfsync everysec
    no-appendfsync-on-rewrite no
    auto-aof-rewrite-percentage 100
    auto-aof-rewrite-min-size 64mb
    aof-load-truncated yes
    
    # Memory settings
    maxmemory 2gb
    maxmemory-policy allkeys-lru
    maxmemory-samples 5
    
    # Lazy freeing
    lazyfree-lazy-eviction yes
    lazyfree-lazy-expire yes
    lazyfree-lazy-server-del yes
    replica-lazy-flush yes
    
    # Security
    requirepass ${REDIS_PASSWORD}
    
    # Client settings
    timeout 0
    tcp-keepalive 300
    
    # Slow log
    slowlog-log-slower-than 10000
    slowlog-max-len 128