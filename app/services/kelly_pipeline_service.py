"""
Kelly Pipeline Service

Deal progression tracking, conversion funnel analytics, revenue attribution,
and pipeline health scoring with AI-powered insights.
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import statistics
import numpy as np
from sqlalchemy import func, and_, or_, desc
from sqlalchemy.orm import Session

from app.database.connection import get_session
from app.models.kelly_crm import Deal, Contact, TouchPoint, CustomerJourney
from app.models.kelly_analytics import ConversationAnalytics, RevenueAttribution
from app.core.redis import redis_manager
from app.core.claude_ai import claude_client

logger = logging.getLogger(__name__)

@dataclass
class PipelineHealth:
    """Pipeline health assessment"""
    overall_score: float
    velocity_score: float
    conversion_score: float
    risk_score: float
    recommendations: List[str]

@dataclass
class ConversionFunnel:
    """Conversion funnel analysis"""
    stages: Dict[str, Dict[str, Any]]
    conversion_rates: Dict[str, float]
    drop_off_points: List[Dict[str, Any]]
    optimization_opportunities: List[str]

@dataclass
class DealRiskAssessment:
    """Deal risk assessment result"""
    risk_level: str
    risk_score: float
    risk_factors: List[str]
    mitigation_actions: List[str]
    probability_adjustment: float

class KellyPipelineService:
    """
    Advanced pipeline management service for Kelly AI system.
    
    Provides deal progression tracking, conversion funnel analysis,
    risk assessment, and pipeline optimization recommendations.
    """
    
    def __init__(self):
        self.cache_ttl = 1800  # 30 minutes cache for pipeline data
        self.stage_progression = {
            'qualification': 0.1,
            'needs_analysis': 0.25,
            'proposal': 0.5,
            'negotiation': 0.75,
            'closed_won': 1.0,
            'closed_lost': 0.0
        }
        
        # Standard sales cycle durations (in days)
        self.typical_stage_durations = {
            'qualification': 7,
            'needs_analysis': 14,
            'proposal': 21,
            'negotiation': 14,
            'closed_won': 0,
            'closed_lost': 0
        }
    
    async def analyze_pipeline_health(
        self,
        account_id: Optional[str] = None,
        time_period_days: int = 90
    ) -> PipelineHealth:
        """
        Analyze overall pipeline health with AI insights.
        
        Args:
            account_id: Optional account filter
            time_period_days: Analysis period in days
            
        Returns:
            Comprehensive pipeline health assessment
        """
        try:
            cutoff_date = datetime.utcnow() - timedelta(days=time_period_days)
            
            async with get_session() as session:\n                # Get deals for analysis\n                deals_query = session.query(Deal).filter(\n                    Deal.created_at >= cutoff_date\n                )\n                \n                if account_id:\n                    deals_query = deals_query.filter(Deal.account_id == account_id)\n                \n                deals = deals_query.all()\n                \n                if not deals:\n                    return PipelineHealth(\n                        overall_score=0.0,\n                        velocity_score=0.0,\n                        conversion_score=0.0,\n                        risk_score=0.0,\n                        recommendations=[\"No deals found in analysis period\"]\n                    )\n                \n                # Calculate velocity score\n                velocity_score = await self._calculate_velocity_score(deals)\n                \n                # Calculate conversion score\n                conversion_score = await self._calculate_conversion_score(deals)\n                \n                # Calculate risk score\n                risk_score = await self._calculate_pipeline_risk_score(deals)\n                \n                # Calculate overall health score\n                overall_score = (\n                    velocity_score * 0.4 +\n                    conversion_score * 0.4 +\n                    (100 - risk_score) * 0.2  # Lower risk = better health\n                )\n                \n                # Generate recommendations\n                recommendations = await self._generate_pipeline_recommendations(\n                    deals, velocity_score, conversion_score, risk_score\n                )\n                \n                return PipelineHealth(\n                    overall_score=overall_score,\n                    velocity_score=velocity_score,\n                    conversion_score=conversion_score,\n                    risk_score=risk_score,\n                    recommendations=recommendations\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error analyzing pipeline health: {str(e)}\")\n            raise\n    \n    async def analyze_conversion_funnel(\n        self,\n        account_id: Optional[str] = None,\n        time_period_days: int = 90\n    ) -> ConversionFunnel:\n        \"\"\"\n        Analyze conversion funnel with stage progression metrics.\n        \n        Args:\n            account_id: Optional account filter\n            time_period_days: Analysis period in days\n            \n        Returns:\n            Detailed conversion funnel analysis\n        \"\"\"\n        try:\n            cutoff_date = datetime.utcnow() - timedelta(days=time_period_days)\n            \n            async with get_session() as session:\n                # Get customer journeys for funnel analysis\n                journeys_query = session.query(CustomerJourney).filter(\n                    CustomerJourney.journey_started_at >= cutoff_date\n                )\n                \n                if account_id:\n                    # Filter by account through contact relationship\n                    journeys_query = journeys_query.join(Contact).filter(\n                        Contact.user_id.like(f\"{account_id}%\")\n                    )\n                \n                journeys = journeys_query.all()\n                \n                # Define funnel stages\n                funnel_stages = ['awareness', 'consideration', 'decision', 'retention']\n                stages_data = {}\n                \n                # Calculate stage metrics\n                for stage in funnel_stages:\n                    stage_journeys = [j for j in journeys if self._journey_reached_stage(j, stage)]\n                    \n                    stages_data[stage] = {\n                        'count': len(stage_journeys),\n                        'percentage': len(stage_journeys) / len(journeys) * 100 if journeys else 0,\n                        'avg_duration_hours': self._calculate_avg_stage_duration(stage_journeys, stage),\n                        'drop_off_rate': self._calculate_stage_drop_off(journeys, stage)\n                    }\n                \n                # Calculate conversion rates between stages\n                conversion_rates = {}\n                for i, stage in enumerate(funnel_stages[:-1]):\n                    current_count = stages_data[stage]['count']\n                    next_count = stages_data[funnel_stages[i + 1]]['count']\n                    \n                    conversion_rate = (next_count / current_count * 100) if current_count > 0 else 0\n                    conversion_rates[f\"{stage}_to_{funnel_stages[i + 1]}\"] = conversion_rate\n                \n                # Identify drop-off points\n                drop_off_points = []\n                for stage, rate in conversion_rates.items():\n                    if rate < 50:  # Less than 50% conversion is concerning\n                        drop_off_points.append({\n                            'stage_transition': stage,\n                            'conversion_rate': rate,\n                            'severity': 'high' if rate < 25 else 'medium'\n                        })\n                \n                # Generate optimization opportunities\n                optimization_opportunities = await self._generate_funnel_optimization_opportunities(\n                    stages_data, conversion_rates, drop_off_points\n                )\n                \n                return ConversionFunnel(\n                    stages=stages_data,\n                    conversion_rates=conversion_rates,\n                    drop_off_points=drop_off_points,\n                    optimization_opportunities=optimization_opportunities\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error analyzing conversion funnel: {str(e)}\")\n            raise\n    \n    async def assess_deal_risk(\n        self,\n        deal_id: str\n    ) -> DealRiskAssessment:\n        \"\"\"\n        Assess risk factors for a specific deal using AI analysis.\n        \n        Args:\n            deal_id: Deal identifier\n            \n        Returns:\n            Comprehensive deal risk assessment\n        \"\"\"\n        try:\n            async with get_session() as session:\n                deal = session.query(Deal).filter(Deal.id == deal_id).first()\n                \n                if not deal:\n                    raise ValueError(f\"Deal not found: {deal_id}\")\n                \n                # Get deal context data\n                contact = session.query(Contact).filter(Contact.id == deal.contact_id).first()\n                touchpoints = session.query(TouchPoint).filter(\n                    TouchPoint.contact_id == deal.contact_id\n                ).order_by(TouchPoint.occurred_at.desc()).limit(10).all()\n                \n                # Calculate risk factors\n                risk_factors = []\n                risk_score = 0.0\n                \n                # Time-based risk factors\n                time_risks = await self._assess_time_based_risks(deal)\n                risk_factors.extend(time_risks['factors'])\n                risk_score += time_risks['score']\n                \n                # Engagement-based risk factors\n                engagement_risks = await self._assess_engagement_risks(deal, contact, touchpoints)\n                risk_factors.extend(engagement_risks['factors'])\n                risk_score += engagement_risks['score']\n                \n                # Stage progression risk factors\n                progression_risks = await self._assess_progression_risks(deal)\n                risk_factors.extend(progression_risks['factors'])\n                risk_score += progression_risks['score']\n                \n                # Competitive risk factors\n                competitive_risks = await self._assess_competitive_risks(deal)\n                risk_factors.extend(competitive_risks['factors'])\n                risk_score += competitive_risks['score']\n                \n                # Determine risk level\n                if risk_score >= 75:\n                    risk_level = 'high'\n                elif risk_score >= 50:\n                    risk_level = 'medium'\n                elif risk_score >= 25:\n                    risk_level = 'low'\n                else:\n                    risk_level = 'minimal'\n                \n                # Generate mitigation actions\n                mitigation_actions = await self._generate_risk_mitigation_actions(\n                    deal, risk_factors, risk_level\n                )\n                \n                # Calculate probability adjustment\n                probability_adjustment = await self._calculate_probability_adjustment(\n                    deal.probability, risk_score\n                )\n                \n                # Store risk assessment\n                deal.risk_level = risk_level\n                deal.risk_factors = risk_factors\n                deal.churn_risk = risk_score / 100\n                await session.commit()\n                \n                return DealRiskAssessment(\n                    risk_level=risk_level,\n                    risk_score=risk_score,\n                    risk_factors=risk_factors,\n                    mitigation_actions=mitigation_actions,\n                    probability_adjustment=probability_adjustment\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error assessing deal risk: {str(e)}\")\n            raise\n    \n    async def track_deal_progression(\n        self,\n        deal_id: str,\n        new_stage: str,\n        progression_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Track deal progression through pipeline stages.\n        \n        Args:\n            deal_id: Deal identifier\n            new_stage: New stage to move to\n            progression_data: Additional progression metadata\n            \n        Returns:\n            Progression tracking results\n        \"\"\"\n        try:\n            async with get_session() as session:\n                deal = session.query(Deal).filter(Deal.id == deal_id).first()\n                \n                if not deal:\n                    raise ValueError(f\"Deal not found: {deal_id}\")\n                \n                old_stage = deal.stage\n                old_probability = deal.probability\n                \n                # Validate stage progression\n                if not self._is_valid_stage_progression(old_stage, new_stage):\n                    raise ValueError(f\"Invalid stage progression from {old_stage} to {new_stage}\")\n                \n                # Update deal stage\n                deal.previous_stage = old_stage\n                deal.stage = new_stage\n                deal.stage_entered_at = datetime.utcnow()\n                \n                # Update probability based on new stage\n                new_probability = self.stage_progression.get(new_stage, deal.probability)\n                deal.probability = new_probability\n                \n                # Calculate stage duration\n                if deal.stage_entered_at and hasattr(deal, 'previous_stage_entered_at'):\n                    stage_duration = (datetime.utcnow() - deal.previous_stage_entered_at).total_seconds() / 3600\n                else:\n                    stage_duration = None\n                \n                # Store progression metadata\n                progression_metadata = {\n                    'old_stage': old_stage,\n                    'new_stage': new_stage,\n                    'old_probability': old_probability,\n                    'new_probability': new_probability,\n                    'stage_duration_hours': stage_duration,\n                    'progression_reason': progression_data.get('reason'),\n                    'progression_notes': progression_data.get('notes'),\n                    'progressed_by': progression_data.get('user_id'),\n                    'progressed_at': datetime.utcnow().isoformat()\n                }\n                \n                # Update deal activities\n                if not deal.activities_completed:\n                    deal.activities_completed = []\n                \n                deal.activities_completed.append({\n                    'type': 'stage_progression',\n                    'data': progression_metadata,\n                    'timestamp': datetime.utcnow().isoformat()\n                })\n                \n                # Calculate velocity metrics\n                velocity_metrics = await self._calculate_deal_velocity_metrics(deal)\n                \n                await session.commit()\n                \n                # Generate next steps recommendations\n                next_steps = await self._generate_next_steps_recommendations(deal, new_stage)\n                \n                return {\n                    'progression_successful': True,\n                    'progression_metadata': progression_metadata,\n                    'velocity_metrics': velocity_metrics,\n                    'next_steps': next_steps,\n                    'updated_deal': {\n                        'id': str(deal.id),\n                        'stage': deal.stage,\n                        'probability': deal.probability,\n                        'stage_entered_at': deal.stage_entered_at.isoformat()\n                    }\n                }\n                \n        except Exception as e:\n            logger.error(f\"Error tracking deal progression: {str(e)}\")\n            raise\n    \n    # Helper methods for calculations and analysis\n    \n    async def _calculate_velocity_score(self, deals: List[Deal]) -> float:\n        \"\"\"Calculate pipeline velocity score\"\"\"\n        if not deals:\n            return 0.0\n        \n        # Calculate average deal cycle time\n        completed_deals = [d for d in deals if d.status in ['won', 'lost'] and d.closed_at]\n        \n        if not completed_deals:\n            return 50.0  # Neutral score if no completed deals\n        \n        cycle_times = []\n        for deal in completed_deals:\n            cycle_time = (deal.closed_at - deal.created_at).days\n            cycle_times.append(cycle_time)\n        \n        avg_cycle_time = statistics.mean(cycle_times)\n        \n        # Compare to industry benchmark (assuming 60 days is optimal)\n        optimal_cycle_time = 60\n        if avg_cycle_time <= optimal_cycle_time:\n            velocity_score = 100\n        else:\n            # Score decreases as cycle time increases\n            velocity_score = max(0, 100 - (avg_cycle_time - optimal_cycle_time) * 2)\n        \n        return velocity_score\n    \n    async def _calculate_conversion_score(self, deals: List[Deal]) -> float:\n        \"\"\"Calculate conversion rate score\"\"\"\n        if not deals:\n            return 0.0\n        \n        total_deals = len(deals)\n        won_deals = len([d for d in deals if d.status == 'won'])\n        \n        conversion_rate = won_deals / total_deals * 100\n        \n        # Score based on conversion rate (30% is considered good)\n        if conversion_rate >= 30:\n            conversion_score = 100\n        elif conversion_rate >= 20:\n            conversion_score = 80\n        elif conversion_rate >= 10:\n            conversion_score = 60\n        else:\n            conversion_score = conversion_rate * 6  # Linear scale for low rates\n        \n        return min(conversion_score, 100)\n    \n    async def _calculate_pipeline_risk_score(self, deals: List[Deal]) -> float:\n        \"\"\"Calculate overall pipeline risk score\"\"\"\n        if not deals:\n            return 0.0\n        \n        risk_factors = []\n        \n        # Stale deals risk\n        stale_deals = [d for d in deals if d.status == 'open' and \n                      (datetime.utcnow() - d.updated_at).days > 30]\n        stale_risk = len(stale_deals) / len(deals) * 50\n        risk_factors.append(stale_risk)\n        \n        # High-value deals at risk\n        total_value = sum(d.deal_value for d in deals if d.status == 'open')\n        at_risk_value = sum(d.deal_value for d in deals if d.status == 'open' and \n                           getattr(d, 'risk_level', 'low') in ['high', 'medium'])\n        \n        value_risk = (at_risk_value / total_value * 100) if total_value > 0 else 0\n        risk_factors.append(value_risk)\n        \n        # Stage distribution risk (too many deals in early stages)\n        early_stage_deals = [d for d in deals if d.status == 'open' and \n                           d.stage in ['qualification', 'needs_analysis']]\n        distribution_risk = len(early_stage_deals) / len(deals) * 30\n        risk_factors.append(distribution_risk)\n        \n        # Calculate weighted average risk\n        overall_risk = statistics.mean(risk_factors)\n        \n        return min(overall_risk, 100)\n    \n    async def _generate_pipeline_recommendations(\n        self,\n        deals: List[Deal],\n        velocity_score: float,\n        conversion_score: float,\n        risk_score: float\n    ) -> List[str]:\n        \"\"\"Generate pipeline improvement recommendations\"\"\"\n        recommendations = []\n        \n        if velocity_score < 70:\n            recommendations.append(\"Focus on reducing deal cycle time through better qualification\")\n            recommendations.append(\"Implement stage-specific activities to accelerate progression\")\n        \n        if conversion_score < 60:\n            recommendations.append(\"Improve lead qualification to focus on higher-probability deals\")\n            recommendations.append(\"Analyze lost deals to identify common failure patterns\")\n        \n        if risk_score > 50:\n            recommendations.append(\"Review stale deals and take action to progress or disqualify\")\n            recommendations.append(\"Implement regular pipeline reviews and deal coaching\")\n        \n        # AI-powered recommendations based on patterns\n        open_deals = [d for d in deals if d.status == 'open']\n        if open_deals:\n            stage_distribution = {}\n            for deal in open_deals:\n                stage_distribution[deal.stage] = stage_distribution.get(deal.stage, 0) + 1\n            \n            # Check for bottlenecks\n            total_open = len(open_deals)\n            for stage, count in stage_distribution.items():\n                if count / total_open > 0.4:  # More than 40% in one stage\n                    recommendations.append(f\"Address bottleneck in {stage} stage - {count} deals stuck\")\n        \n        return recommendations[:5]  # Return top 5 recommendations\n    \n    def _journey_reached_stage(self, journey: CustomerJourney, stage: str) -> bool:\n        \"\"\"Check if journey reached a specific stage\"\"\"\n        if stage == 'awareness':\n            return journey.awareness_entered_at is not None\n        elif stage == 'consideration':\n            return journey.consideration_entered_at is not None\n        elif stage == 'decision':\n            return journey.decision_entered_at is not None\n        elif stage == 'retention':\n            return journey.retention_entered_at is not None\n        return False\n    \n    def _calculate_avg_stage_duration(self, journeys: List[CustomerJourney], stage: str) -> float:\n        \"\"\"Calculate average duration in a specific stage\"\"\"\n        durations = []\n        \n        for journey in journeys:\n            if stage == 'awareness' and journey.awareness_duration_hours:\n                durations.append(journey.awareness_duration_hours)\n            elif stage == 'consideration' and journey.consideration_duration_hours:\n                durations.append(journey.consideration_duration_hours)\n            elif stage == 'decision' and journey.decision_duration_hours:\n                durations.append(journey.decision_duration_hours)\n            elif stage == 'retention' and journey.retention_duration_hours:\n                durations.append(journey.retention_duration_hours)\n        \n        return statistics.mean(durations) if durations else 0.0\n    \n    def _calculate_stage_drop_off(self, all_journeys: List[CustomerJourney], stage: str) -> float:\n        \"\"\"Calculate drop-off rate at a specific stage\"\"\"\n        reached_stage = len([j for j in all_journeys if self._journey_reached_stage(j, stage)])\n        \n        # Find next stage\n        stages = ['awareness', 'consideration', 'decision', 'retention']\n        if stage in stages and stages.index(stage) < len(stages) - 1:\n            next_stage = stages[stages.index(stage) + 1]\n            reached_next = len([j for j in all_journeys if self._journey_reached_stage(j, next_stage)])\n            \n            drop_off_rate = ((reached_stage - reached_next) / reached_stage * 100) if reached_stage > 0 else 0\n            return drop_off_rate\n        \n        return 0.0\n    \n    async def _generate_funnel_optimization_opportunities(\n        self,\n        stages_data: Dict[str, Dict[str, Any]],\n        conversion_rates: Dict[str, float],\n        drop_off_points: List[Dict[str, Any]]\n    ) -> List[str]:\n        \"\"\"Generate funnel optimization opportunities\"\"\"\n        opportunities = []\n        \n        # Analyze drop-off points\n        for drop_off in drop_off_points:\n            stage_transition = drop_off['stage_transition']\n            rate = drop_off['conversion_rate']\n            \n            if 'awareness_to_consideration' in stage_transition:\n                opportunities.append(f\"Improve content quality and engagement in awareness stage (current conversion: {rate:.1f}%)\")\n            elif 'consideration_to_decision' in stage_transition:\n                opportunities.append(f\"Enhance product demonstrations and proof of value (current conversion: {rate:.1f}%)\")\n            elif 'decision_to_retention' in stage_transition:\n                opportunities.append(f\"Streamline closing process and remove friction (current conversion: {rate:.1f}%)\")\n        \n        # Analyze stage durations\n        for stage, data in stages_data.items():\n            avg_duration = data.get('avg_duration_hours', 0)\n            if avg_duration > 168:  # More than a week\n                opportunities.append(f\"Reduce time spent in {stage} stage (currently {avg_duration/24:.1f} days average)\")\n        \n        return opportunities[:5]  # Return top 5 opportunities\n    \n    async def _assess_time_based_risks(self, deal: Deal) -> Dict[str, Any]:\n        \"\"\"Assess time-based risk factors for a deal\"\"\"\n        risk_factors = []\n        risk_score = 0.0\n        \n        # Deal age risk\n        deal_age_days = (datetime.utcnow() - deal.created_at).days\n        if deal_age_days > 90:\n            risk_factors.append(f\"Deal is {deal_age_days} days old - may be stale\")\n            risk_score += 20\n        elif deal_age_days > 60:\n            risk_factors.append(f\"Deal is {deal_age_days} days old - monitor closely\")\n            risk_score += 10\n        \n        # Time in current stage\n        if deal.stage_entered_at:\n            stage_duration_days = (datetime.utcnow() - deal.stage_entered_at).days\n            typical_duration = self.typical_stage_durations.get(deal.stage, 14)\n            \n            if stage_duration_days > typical_duration * 2:\n                risk_factors.append(f\"Deal stuck in {deal.stage} stage for {stage_duration_days} days\")\n                risk_score += 25\n            elif stage_duration_days > typical_duration:\n                risk_factors.append(f\"Deal in {deal.stage} stage longer than typical\")\n                risk_score += 10\n        \n        # Expected close date risk\n        if deal.expected_close_date < datetime.utcnow().date():\n            days_overdue = (datetime.utcnow().date() - deal.expected_close_date).days\n            risk_factors.append(f\"Deal is {days_overdue} days past expected close date\")\n            risk_score += min(30, days_overdue * 2)\n        \n        return {'factors': risk_factors, 'score': min(risk_score, 50)}\n    \n    async def _assess_engagement_risks(self, deal: Deal, contact: Contact, touchpoints: List[TouchPoint]) -> Dict[str, Any]:\n        \"\"\"Assess engagement-based risk factors\"\"\"\n        risk_factors = []\n        risk_score = 0.0\n        \n        if not touchpoints:\n            risk_factors.append(\"No recent touchpoints - low engagement\")\n            risk_score += 30\n            return {'factors': risk_factors, 'score': risk_score}\n        \n        # Recent engagement analysis\n        recent_touchpoints = [tp for tp in touchpoints if \n                            (datetime.utcnow() - tp.occurred_at).days <= 14]\n        \n        if not recent_touchpoints:\n            risk_factors.append(\"No touchpoints in last 14 days\")\n            risk_score += 25\n        elif len(recent_touchpoints) < 2:\n            risk_factors.append(\"Low engagement frequency\")\n            risk_score += 15\n        \n        # Engagement quality analysis\n        if recent_touchpoints:\n            avg_engagement = statistics.mean([tp.engagement_quality for tp in recent_touchpoints])\n            if avg_engagement < 0.3:\n                risk_factors.append(\"Low engagement quality scores\")\n                risk_score += 20\n            elif avg_engagement < 0.5:\n                risk_factors.append(\"Below average engagement quality\")\n                risk_score += 10\n        \n        # Sentiment analysis\n        negative_touchpoints = [tp for tp in recent_touchpoints if tp.sentiment == 'negative']\n        if len(negative_touchpoints) > len(recent_touchpoints) / 2:\n            risk_factors.append(\"Majority of recent interactions have negative sentiment\")\n            risk_score += 25\n        \n        return {'factors': risk_factors, 'score': min(risk_score, 40)}\n    \n    async def _assess_progression_risks(self, deal: Deal) -> Dict[str, Any]:\n        \"\"\"Assess stage progression risk factors\"\"\"\n        risk_factors = []\n        risk_score = 0.0\n        \n        # Probability vs stage mismatch\n        expected_probability = self.stage_progression.get(deal.stage, 0.5)\n        if deal.probability < expected_probability - 0.2:\n            risk_factors.append(f\"Probability ({deal.probability:.0%}) low for {deal.stage} stage\")\n            risk_score += 15\n        \n        # Backward stage movement\n        if deal.previous_stage and deal.stage:\n            stage_order = list(self.stage_progression.keys())\n            if deal.stage in stage_order and deal.previous_stage in stage_order:\n                current_index = stage_order.index(deal.stage)\n                previous_index = stage_order.index(deal.previous_stage)\n                \n                if current_index < previous_index:\n                    risk_factors.append(\"Deal moved backward in pipeline\")\n                    risk_score += 20\n        \n        return {'factors': risk_factors, 'score': min(risk_score, 30)}\n    \n    async def _assess_competitive_risks(self, deal: Deal) -> Dict[str, Any]:\n        \"\"\"Assess competitive risk factors\"\"\"\n        risk_factors = []\n        risk_score = 0.0\n        \n        # Check for competitor mentions\n        if deal.competitors:\n            competitor_count = len(deal.competitors)\n            if competitor_count > 2:\n                risk_factors.append(f\"High competitive pressure - {competitor_count} competitors\")\n                risk_score += 20\n            elif competitor_count > 0:\n                risk_factors.append(f\"Competitive situation - {competitor_count} competitors\")\n                risk_score += 10\n        \n        return {'factors': risk_factors, 'score': min(risk_score, 20)}\n    \n    async def _generate_risk_mitigation_actions(\n        self,\n        deal: Deal,\n        risk_factors: List[str],\n        risk_level: str\n    ) -> List[str]:\n        \"\"\"Generate risk mitigation action recommendations\"\"\"\n        actions = []\n        \n        if risk_level in ['high', 'medium']:\n            actions.append(\"Schedule immediate stakeholder meeting to address concerns\")\n            actions.append(\"Review and update deal strategy with sales team\")\n        \n        # Factor-specific actions\n        for factor in risk_factors:\n            if \"stale\" in factor.lower() or \"old\" in factor.lower():\n                actions.append(\"Conduct deal review and qualification refresh\")\n            elif \"engagement\" in factor.lower():\n                actions.append(\"Increase touchpoint frequency and vary communication channels\")\n            elif \"negative sentiment\" in factor.lower():\n                actions.append(\"Address customer concerns and objections proactively\")\n            elif \"competitor\" in factor.lower():\n                actions.append(\"Develop competitive strategy and unique value proposition\")\n            elif \"stuck\" in factor.lower():\n                actions.append(\"Identify and remove blockers to stage progression\")\n        \n        return list(set(actions))[:5]  # Return unique actions, max 5\n    \n    async def _calculate_probability_adjustment(\n        self,\n        current_probability: float,\n        risk_score: float\n    ) -> float:\n        \"\"\"Calculate adjusted probability based on risk score\"\"\"\n        \n        # Adjust probability down based on risk\n        risk_impact = risk_score / 100 * 0.3  # Max 30% reduction\n        adjusted_probability = current_probability * (1 - risk_impact)\n        \n        return max(0.01, min(1.0, adjusted_probability))\n    \n    def _is_valid_stage_progression(self, old_stage: str, new_stage: str) -> bool:\n        \"\"\"Validate if stage progression is allowed\"\"\"\n        stage_order = list(self.stage_progression.keys())\n        \n        if old_stage not in stage_order or new_stage not in stage_order:\n            return False\n        \n        old_index = stage_order.index(old_stage)\n        new_index = stage_order.index(new_stage)\n        \n        # Allow forward progression or moving to closed stages\n        return new_index >= old_index or new_stage in ['closed_won', 'closed_lost']\n    \n    async def _calculate_deal_velocity_metrics(self, deal: Deal) -> Dict[str, Any]:\n        \"\"\"Calculate velocity metrics for a deal\"\"\"\n        \n        # Calculate time in current stage\n        if deal.stage_entered_at:\n            time_in_stage = (datetime.utcnow() - deal.stage_entered_at).total_seconds() / 3600\n        else:\n            time_in_stage = 0\n        \n        # Calculate total deal duration\n        total_duration = (datetime.utcnow() - deal.created_at).total_seconds() / 3600\n        \n        # Calculate expected remaining time\n        remaining_stages = [s for s in self.typical_stage_durations.keys() \n                          if self.stage_progression[s] > self.stage_progression.get(deal.stage, 0)]\n        expected_remaining_days = sum(self.typical_stage_durations[s] for s in remaining_stages)\n        \n        return {\n            'time_in_current_stage_hours': time_in_stage,\n            'total_duration_hours': total_duration,\n            'expected_remaining_days': expected_remaining_days,\n            'velocity_score': min(100, max(0, 100 - (time_in_stage / 24 - self.typical_stage_durations.get(deal.stage, 14)) * 5))\n        }\n    \n    async def _generate_next_steps_recommendations(\n        self,\n        deal: Deal,\n        new_stage: str\n    ) -> List[str]:\n        \"\"\"Generate next steps recommendations based on new stage\"\"\"\n        \n        stage_recommendations = {\n            'qualification': [\n                \"Conduct discovery call to understand needs\",\n                \"Confirm budget and decision-making process\",\n                \"Identify key stakeholders and influencers\"\n            ],\n            'needs_analysis': [\n                \"Present tailored solution demonstration\",\n                \"Gather detailed requirements and success criteria\",\n                \"Provide relevant case studies and references\"\n            ],\n            'proposal': [\n                \"Deliver customized proposal and pricing\",\n                \"Schedule stakeholder presentation\",\n                \"Address objections and concerns\"\n            ],\n            'negotiation': [\n                \"Finalize contract terms and pricing\",\n                \"Prepare implementation timeline\",\n                \"Coordinate legal and procurement reviews\"\n            ]\n        }\n        \n        return stage_recommendations.get(new_stage, [\"Continue relationship building and value demonstration\"])\n\n# Create global pipeline service instance\nkelly_pipeline_service = KellyPipelineService()"